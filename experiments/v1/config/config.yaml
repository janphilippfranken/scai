# refer to arguments.py for full details
hydra:
  run:
    dir: sim_res/${sim.episode_id}
  # job:
    # env_set: # will be useful for running things on ccn
    #   TOKENIZERS_PARALLELISM: "false" 
    #   CUDA_VISIBLE_DEVICES: "0,1"  # make sure to keep this number small to avoid crash on ccn (HF Trainer will automatically utilise all GPUs and crashed last time when i forgot to export this)
    #   WANDB_DISABLED: true # deprecated soon, need to change but sufficient for now...
    #   MASTER_ADDR: "node13-ccncluster" # only needed if not using tochrun or any higher-level abstractions (accelerate, trainer)
    #   MASTER_PORT: "12355" # same for this one

sim:
  n_user: 2
  n_assistant: 2
  system_k: 5
  chat_k: 5
  user_k: 2
  assistant_k: 2
  assistant_system_k: 1
  episode_id: "episode_1"
  episode_name: "episode_1"
  verbose: true # if true we wont run models but just print the prompts.
  system_message: " "
  n_runs: 5
  model: "gpt-3.5-turbo-0301"

api:
  assistant:
    crfm_api_key: "" # gpt4 philipp
    # model_name: "openai/gpt-3.5-turbo-0301" # gpt 3
    model_name: "openai/gpt-4-0314"
    max_tokens: 50
    num_completions: 1
    request_timeout: 10
    verbose: false
    temperature: 0.5
  user:
    crfm_api_key: "" # gpt4 philipp
    # model_name: "openai/gpt-3.5-turbo-0301" # gpt 3
    model_name: "openai/gpt-4-0314" 
    max_tokens: 50
    num_completions: 1
    request_timeout: 10
    verbose: false
    temperature: 0.5
  meta:
    crfm_api_key: "" # gpt4 philipp
    # model_name: "openai/gpt-3.5-turbo-0301" # gpt 3
    model_name: "openai/gpt-4-0314" 
    max_tokens: 200
    num_completions: 1
    request_timeout: 10
    verbose: false
    temperature: 0.5
