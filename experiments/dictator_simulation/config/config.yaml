# Filename: config.yaml
# ------------------------
# A brief outline of the config file:
# sim:
#   Here you find basic run characteristics that are separate from run content
# ...
# env:
#   env contains all essential run details, such as:
#   ...
#   Whether the run characteristics are randomly generated from a provided pool or not, whether fixed agents have set splitting behavior
#   ...
#   EDGE_CASES:
#     edge_cases contains whether the model's capability to generalize is being tested or not. Includes parameters-to-set if so.
#   ...
#   RANDOM:
#     Random contains the run characteristics that should be randomized from buckets that YOU set if you want a random run, such as currency, amount, and interaction types
#   ...
#   VARIATION:
#     variation contains all of the ways that we implemented different experiments, being:
#   1. The utility that fixed-agents share
#   2. Varying utility amoung fixed agents within the population of fixed agents itself
#   3. The manners that fixed-agents share 
#   4. Varying the manners among fixed agents within the population of fixed agents itself
#   5. Varying the prior of the flexible agents
#   6. Varying whether fixed agents have different utilities for different types of currency
#   ...
#   EXPERIMENT CHARACTERISTICS:
#     here we find all of the important, nitty-gritty numbers and stringsthat define the run characteristics, such as:
#   1. The total number of interactions between agents in a single iteration of meta-prompt
#   2. The amounts of currency that the agents split in each iteration of meta-prompt
#   3. The pool of currencies that random draws from (or you set) to be split for each iteration of meta-prompt
#   4. The prompts that we use for each run
#   5. The number and type of interaction between agents, eg fixed-fixed, fixed-flex, or flex-flex out of the total interactions
#   ...
#
#  ------------------------------------------------ ENV ENDS HERE --------------------------------------------------
#
# TEMPLATES:
#   templates contains the user templates that we draw data from, as well as the interaction strings that we use for each run of meta-prompt.
# ...
# COMBINE:
#   combine is a utility function that is used to aggregate and plot data from a specified folder. It plots all of the data on one axes, allowing for comparison
# ...
# PARAMETERS:
#   has model parameters such as token limit and temperature
# ...

hydra:
  run:
    dir: experiments/${sim.sim_dir}/${sim.sim_id}

sim:
  # ------------ I/O PARAMETERS, MODEL TYPES, VERBOSITY ------------ #
  sim_dir: "generalizations/question_asking/OOD_currency" # this is the name of the directory where the results will be saved
  description: "" # this is the description of the simulation
  sim_id: "0"
  model_name: "openai/gpt-4-0314" # for openai api use "gpt-4", for crfm use "openai/gpt-4-0314"
  test_run: false # if false this uses tokens, otherwise just prints the prompt
  verbose: true # if false, no responses are printed during simulation
  system_message: "Some principle was given to the flexible agents" # start developer constitution / social contract is given according to system

env:
  propose_decide_alignment: false # if true, then the propose-decide alignment is used, corrensponding to utilities_dict_for_all_2 and experiment 4 (sociopath)
  manual_run: false # if false this generates trials with variance, otherwise defaults to manual agents and interactions below

  # ------------ EDGE_CASES: TESTS OF GENERALIZATION OF THE LEARNED CONTRACT TO OUT OF DISTRIBUTION CONTEXTS ------------ #
  edge_cases: 
    test_edge_cases: True # If set to true, then generalization cases will be tested
    activate: False # switch indicating whether we are actively testing generalization, should always be false during configuration
    generate_new_data: True # Otherwise, data will be used from the use_existing_data_path parameter below
    use_existing_data_path: "experiments/generalizations/question_asking"
    selected_contract: "" # Placeholder field meant to hold the selected contract for the edge-case run
    n_rand_iter: 2 # Number of experiements that are run
    reason: 
      include_reason: False # If set to true, the model will be prompted to justify its split in a generalization case
    prior:
      include_prior: False # If set to true the model will be prompted with the prior found in "prior" below
      prior: "altruistic"
    conditions: 
      amount: # These set the amount to-be-split for the edge-case run
        set_amount: true 
        min: 10
        max: 100
      currency: # Sets the currency for the edge-case run
        set_currency: true
        currencies: # Types of currencies that you want to include
          #- "apples"
          # - "blankets"
          #- "dollars"
          #- "subscriptions to youtube channels"
          - "lifesaving portions of medicine"
          #- "grams of medicine"
          #- "pints of blood"
          #- "liters of baby formula"
      context: false # If set to true, includes situations in which these splits are being made (not implemented yet)
      ask_question: true
    plot_save_path: "generalizations/edge_case"

  # ------------ RANDOMLY GENERATES CURRENCIES, AMOUNTS, AND INTERACTIONS TYPES FROM PROVIDED PARAMETERS FOUND BELOW ------------ #
  random:
    n_rand_iter: 2 # number of times the entire functionality is run, at least 2
    rand_variables:
      currency: true # if true, the currency will vary for each random iteration
      amount: true # if true, amount-to-be-split will vary for each random iteration
      n_fixed_inter: false # if true, the number of intra-fixed-policy agent interactions varies for each random iteration
      n_mixed_inter: false # if true, the number of flexible-fixed policy agent interactions varies

  # ------------ VARIATION - HOW WE CHANGE WHAT AGENTS HAVE WHAT UTILITY, MANNERS, CURRENCY, AND PRIORS PER RUN ------------ #
  single_fixed_utility: "altruistic" # the default utility for the fixed users to adpot

  vary_fixed_population_utility: 
    vary_utilities: false # if true, the utilities will vary between fixed policy agents
    dictator_decider_equal: true # if true, numbers of dictators and deciders are equal
    utility_percentages:
      - 0.5
      - 0.5
    utilities: "selfish,altruistic" # utilities that vary between fixed agents

  single_fixed_manners: "neutral" # The default manners that all fixed agents have
  
  vary_manners: # If vary_manners is true, then manners will be varied between fixed agents
    vary: false
    manners_percentages: # These will dictate the splits of the manners found in manners, below
      - 0.2
      - 0.2
      - 0.6
    manners: "neutral,rude,sychophantic" # The manners you want fixed agents to have

  flex_agent_start_utility: # The flexible agents' prior, set to be randomized by default
    randomized: true
    multi_agent: false
    utility_percentages: # Percentages that dictate how many flexible agents will have the utilities found below
      - 0.5
      - 0.5
    utilities: "altruistic,selfish" # The utilities that the flexible agents have

  vary_currency_utility:
    vary_utilities: false # if true, then each fixed-policy-agent will have varying utilities per currency
    utilities: "altruistic,fair,selfish" # utilities that vary between fixed agents
  
  # ------------ EXPERIMENT CHARACTERISTICS - HOW WE CHANGE THE AVAILABLE CURRENCIES, AMOUNTS, INTERACTIONS, AND PROMPTS PER RUN ------------ #
  n_total_interactions: 12 # the number of interactions between agents per run

  n_runs: 3 # The number of meta-prompt runs per experiment
  amounts_per_run: # Contains the amounts per run, should match with the n_runs parameter
    - 10
    - 10
    - 10
    - 10
    - 10
  currencies: # Currencies to-be-split
    #- "apples"
    - "blankets"
    # - "dollars"
    #- "subscriptions to youtube channels"
    #- "lifesaving portions of medicine"
  currencycounter: "" # placeholder for reference currency
  task_prompt: "task_prompt_1"
  meta_prompt: "meta_prompt_3"
  n_fixed_inter: 6 # The number of fixed-fixed interactions between agents
  n_mixed_inter: 6 # The number of fixed-flex or flex-fixed interactions between agents
  n_flex_inter: 0 # The number of flex-flex interactions between agents

# ------------ AGENT AND INTERACTION TEMPLATES IF YOU WOULD LIKE TO SET YOUR OWN RUNS (SET MANUAL RUN TO TRUE) ------------ #
agents: # These are templates for the agents in case you would like to make your own
  fixed_agents: 
    - name: "fixed_agent_1"
      manners: "neutral"
      utilities:    
        dollars: "altruistic"
        apples: "altruistic"
  flex_agents:
    - name: "flex_agent_1"
      manners: "neutral"
      initial_util: "fair"

interactions:
  all_same: true #should be true if manual runs is false
  runs: # Dictates what types of interactions are had per run. Again, these are templates
    run_1:             
      - "fixed_agent_2-fixed_agent_1-dollars"
      - "flex_agent_4-fixed_agent_3-dollars"
      - "fixed_agent_4-flex_agent_3-dollars"
      - "flex_agent_2-flex_agent_1-dollars"

# ------------ COMBINES GRAPHS FROM DIFFERENT EXPERIMENTAL RUNS ------------ #
combine:
  combine_graph_directory: "experiments/batch_1/experiment_3/20runs/1v9_sycophantic"
  combine_output_directory: experiments/solar_final/manners_ambiguity/
  combine_graph_labels:
    # - "50% altruistic + 50% selfish"
    # - "80% altruistic + 20% selfish"
    # - "20% altruistic + 80% selfish"
    - "altruistic"
    - "fair"
    - "selfish"
    - "fixed"
    - "flexible"
    # - "Selfish"
    # - "Fixed-agent"
    # - "Flexible-agent"

# ------------ MODEL PARAMETERS ------------ #
api_crfm:
  assistant:
    model_name: "openai/gpt-4-0314"
    max_tokens: 300 # these are the actual token limits
    temperature: 0.401
  user:
    model_name: "openai/gpt-4-0314" 
    max_tokens: 150 # these are the actual token limits
    temperature: 0.01 # we want users to be low on temperature to avoid random variation in ratings
  meta:
    model_name: "openai/gpt-4-0314" 
    max_tokens: 400 # these are the actual token limits
    temperature: 0.001
  oracle:
    model_name: "openai/gpt-4-0314"
    max_tokens: 150
    temperature: 0

api_openai:
  assistant:
    model_name: "gpt-4"
    max_tokens: 250 # these are the actual token limits
    temperature: 0.0
  user:
    model_name: "gpt-4"
    max_tokens: 50 # these are the actual token limits
    temperature: 0.0
  meta:
    model_name: "gpt-4"
    max_tokens: 150 # these are the actual token limits
    temperature: 0.0
  oracle:
    model_name: "openai/gpt-4-0314"
    max_tokens: 150
    temperature: 0