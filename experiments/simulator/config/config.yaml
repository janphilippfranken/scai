hydra:
  run:
    dir: sim_res/${sim.sim_dir}/${sim.sim_id}

sim:
  sim_dir: "sim_1" 
  sim_id: "0_demo" 
  model_name: "openai/gpt-4-0314" # for openai api use "gpt-4", for crfm use "openai/gpt-4-0314"
  test_run: true # if false this uses tokens, otherwise just print the prompt
  verbose: true
  n_runs: 1
  n_turns: 2
  system_k: 1 # memory for meta-prompt (i.e. how many past constitutions do we see)
  chat_k: 2 # chat memory of the assistant / user (i.e. how many past turns do we see, currently only working for 0)
  system_message: "1. You are a helpful AI Assistant." #Â start constitution
  task_prompt: "task_prompt_4"
  user_prompts: 
    - "user_prompt_1" # 
    - "user_prompt_2" # 
    - "user_prompt_5" # unabomber
  assistant_prompts: 
    - "assistant_prompt_1"
    - "assistant_prompt_1"
    - "assistant_prompt_1"
  meta: "meta_1"
  metric_prompt: "metric_prompt_1"
  max_tokens_assistant: 100 # these are the token limits displayed in prompts
  max_tokens_user: 50 # these are the token limits displayed in prompts
  max_tokens_meta: 100 # these are the token limits displayed in prompts

api_crfm:
  assistant:
    model_name: "openai/gpt-4-0314"
    max_tokens: 300 # these are the actual token limits
    temperature: 0.2
  user:
    model_name: "openai/gpt-4-0314" 
    max_tokens: 150 # these are the actual token limits
    temperature: 0.2
  meta:
    model_name: "openai/gpt-4-0314" 
    max_tokens: 400 # these are the actual token limits
    temperature: 0.1

api_openai:
  assistant:
    model_name: "gpt-4"
    max_tokens: 100 # these are the actual token limits
    temperature: 0.2
  user:
    model_name: "gpt-4"
    max_tokens: 50 # these are the actual token limits
    temperature: 0.2
  meta:
    model_name: "gpt-4"
    max_tokens: 150 # these are the actual token limits
    temperature: 0.1