hydra:
  run:
    dir: sim_res/${sim.sim_dir}/${sim.sim_id}

sim:
  sim_dir: "sim_3" 
  sim_id: "0" 
  model_name: "openai/gpt-4-0314" # for openai api use "gpt-4", for crfm use "openai/gpt-4-0314"
  test_run: false # if false this uses tokens, otherwise just print the prompt
  verbose: true
  n_runs: 5
  n_turns: 3

  system_message: "1. You are a helpful AI Assistant." #Â start constitution
  task_prompt: "task_prompt_3"
  user_prompts: 
    - "user_prompt_1" # 
    - "user_prompt_2" 
    # - "user_prompt_5" unabomber
  assistant_prompts: 
    - "assistant_prompt_1"
    - "assistant_prompt_1"
    # - "assistant_prompt_1"
  meta_prompt: "meta_prompt_1"
  metric_prompt: "metric_prompt_1"
  max_tokens_assistant: 100 # these are the token limits displayed in prompts
  max_tokens_user: 50 # these are the token limits displayed in prompts
  max_tokens_meta: 100 # these are the token limits displayed in prompts

api_crfm:
  assistant:
    model_name: "openai/gpt-4-0314"
    max_tokens: 300 # these are the actual token limits
    temperature: 0.5
  user:
    model_name: "openai/gpt-4-0314" 
    max_tokens: 150 # these are the actual token limits
    temperature: 0.5
  meta:
    model_name: "openai/gpt-4-0314" 
    max_tokens: 400 # these are the actual token limits
    temperature: 0.5

api_openai:
  assistant:
    model_name: "gpt-4"
    max_tokens: 100 # these are the actual token limits
    temperature: 0.5
  user:
    model_name: "gpt-4"
    max_tokens: 50 # these are the actual token limits
    temperature: 0.5
  meta:
    model_name: "gpt-4"
    max_tokens: 150 # these are the actual token limits
    temperature: 0.5